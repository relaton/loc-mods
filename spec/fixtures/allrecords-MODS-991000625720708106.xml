<?xml version="1.0" encoding="utf-8"?>
<modsCollection xmlns="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-7.xsd">
<mods version="3.7">
      <titleInfo>
         <title>Four principles of explainable artificial intelligence</title>
      </titleInfo>
      <name type="personal" usage="primary">
         <namePart>Phillips, P. Jonathon.</namePart>
      </name>
      <name type="personal">
         <namePart>Phillips, P. Jonathon.</namePart>
      </name>
      <name type="personal">
         <namePart>Hahn, Carina A.</namePart>
      </name>
      <name type="personal">
         <namePart>Fontana, Peter C.</namePart>
      </name>
      <name type="personal">
         <namePart>Yates, Amy N.</namePart>
      </name>
      <name type="personal">
         <namePart>Greene, Kristen.</namePart>
      </name>
      <name type="personal">
         <namePart>Broniatowski, David A.</namePart>
      </name>
      <name type="personal">
         <namePart>Przybocki, Mark A.</namePart>
      </name>
      <name type="corporate">
         <namePart>National Institute of Standards and Technology (U.S.)</namePart>
         <namePart>Information Technology Laboratory</namePart>
      </name>
      <typeOfResource>text</typeOfResource>
      <genre authority="marcgt">encyclopedia</genre>
      <genre authority="rdacontent">text</genre>
      <originInfo>
         <place>
            <placeTerm type="code" authority="marccountry">ot</placeTerm>
         </place>
         <dateIssued encoding="marc">2021</dateIssued>
         <issuance>monographic</issuance>
      </originInfo>
      <originInfo eventType="publisher">
         <place>
            <placeTerm type="text">Gaithersburg, MD :</placeTerm>
         </place>
         <publisher>U.S. Dept. of Commerce, National Institute of Standards and
                Technology ;</publisher>
         <dateIssued>2021-09-29.</dateIssued>
      </originInfo>
      <physicalDescription>
         <form authority="marcform">print</form>
         <form type="media" authority="rdamedia">computer</form>
         <form type="carrier" authority="rdacarrier">online resource</form>
         <extent>1 online resource (43 pages) : illustrations (black and white)</extent>
      </physicalDescription>
      <abstract displayLabel="Abstract">We introduce four principles for explainable artificial intelligence
                (AI) that comprise fundamental properties for explainable AI systems. We propose
                that explainable AI systems deliver accompanying evidence or reasons for outcomes
                and processes; provide explanations that are understandable to individual users;
                provide explanations that correctly reflect the system s process for generating the
                output; and that a system only operates under conditions for which it was designed
                and when it reaches sufficient confidence in its output. We have termed these four
                principles as explanation, meaningful, explanation accuracy, and knowledge limits,
                respectively. Through significant stakeholder engagement, these four principles were
                developed to encompass the multidisciplinary nature of explainable AI, including the
                fields of computer science, engineering, and psychology. Because one-sizefits-all
                explanations do not exist, different users will require different types of
                explanations. We present five categories of explanation and summarize theories of
                explainable AI. We give an overview of the algorithms in the field that cover the
                major classes of explainable algorithms. As a baseline comparison, we assess how
                well explanations provided by people follow our four principles. This assessment
                provides insights to the challenges of designing explainable AI systems.</abstract>
      <note type="statement of responsibility">P. Jonathon Phillips; Carina A. Hahn; Peter C. Fontana; Amy N. Yates;
                Kristen Greene; David A. Broniatowski; Mark A. Przybocki.</note>
      <note>September 2021.</note>
      <note>Title from PDF title page (viewed October 1, 2021).</note>
      <note type="bibliography">Includes bibliographical references.</note>
      <note type="venue">Approved by the NIST Editorial Review Board on 2021-09-29</note>
      <note type="system details">Mode of access: World Wide Web.</note>
      <note type="system details">Systems requirements: Adobe Acrobat PDF reader.</note>
      <subject authority="lcsh">
         <topic>Artificial intelligence</topic>
      </subject>
      <location>
         <url displayLabel="electronic resource" usage="primary display">https://doi.org/10.6028/NIST.IR.8312</url>
      </location>
      <relatedItem type="series">
         <titleInfo>
            <title>NISTIR; NIST IR; NIST interagency report; NIST internal
                report</title>
            <partNumber>8312</partNumber>
         </titleInfo>
      </relatedItem>
      <identifier type="oclc">1389889954</identifier>
      <identifier type="oclc">on1389889954</identifier>
      <recordInfo>
         <descriptionStandard>rda</descriptionStandard>
         <recordContentSource authority="marcorg">NBS</recordContentSource>
         <recordCreationDate encoding="marc">230711</recordCreationDate>
         <recordChangeDate encoding="iso8601">20240401111420.0</recordChangeDate>
         <recordIdentifier>991000625720708106</recordIdentifier>
         <recordOrigin>Converted from MARCXML to MODS version 3.7 using MARC21slim2MODS3-7.xsl
				(Revision 1.140 20200717)</recordOrigin>
         <languageOfCataloging>
            <languageTerm authority="iso639-2b" type="code">eng</languageTerm>
         </languageOfCataloging>
      </recordInfo>
   </mods></modsCollection>
